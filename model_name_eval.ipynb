{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "974ed0e0-36a0-490a-b217-fe60a7422f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "f='./depmap/Model.csv.gz'\n",
    "host='127.0.0.1'\n",
    "port='9999'\n",
    "model='meta-llama/Meta-Llama-3-70B-Instruct'\n",
    "\n",
    "port='8999'\n",
    "model='mistral-community/Mixtral-8x22B-v0.1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b40a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Set OpenAI's API key and API base to use vLLM's API server.\n",
    "openai_api_key = 'cmsc-35360'\n",
    "openai_api_key = 'EMPTY'\n",
    "\n",
    "openai_api_base = f\"http://{host}:{port}/v1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1c2af72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_data(f):\n",
    "    df=pd.read_csv(f)\n",
    "    print(f'done importing dataframe (rows, columns) = {df.shape}.')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84b368e7-4869-4bd8-925e-daa395549f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def select_random_element_not_equal_to(array, correct):\n",
    "    '''\n",
    "    Given an array of unique answers, select an answer not\n",
    "    equal to the correct answer.\n",
    "    '''\n",
    "    if len(array) == 0:\n",
    "        raise ValueError(\"The array is empty\")\n",
    "\n",
    "    # Filter out elements equal to `correct`\n",
    "    filtered_array = [element for element in array if element != correct]\n",
    "    \n",
    "    if not filtered_array:\n",
    "        raise ValueError(\"No valid elements to choose from\")\n",
    "\n",
    "    # Select a random element from the filtered list\n",
    "    return random.choice(filtered_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70546a55-6269-4c69-a75c-208ad0af1e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_question(df, index, array):\n",
    "    '''\n",
    "    Construct a multiple choice question from df using row at index.\n",
    "    '''\n",
    "    if index < 0 or index >= len(df):\n",
    "        raise IndexError(\"Index out of bounds\")\n",
    "    \n",
    "    cell_line_name = df.iloc[index]['CellLineName']\n",
    "    correct_answer = df.iloc[index]['OncotreePrimaryDisease']\n",
    "\n",
    "    wrong_answer_1 = select_random_element_not_equal_to(array, correct_answer)\n",
    "    wrong_answer_2 = select_random_element_not_equal_to(array, correct_answer)\n",
    "    wrong_answer_3 = select_random_element_not_equal_to(array, correct_answer)\n",
    "\n",
    "    while wrong_answer_1 == wrong_answer_2 or wrong_answer_1 == wrong_answer_3 or wrong_answer_2 == wrong_answer_3:\n",
    "        wrong_answer_1 = select_random_element_not_equal_to(array, correct_answer)\n",
    "        wrong_answer_2 = select_random_element_not_equal_to(array, correct_answer)\n",
    "        wrong_answer_3 = select_random_element_not_equal_to(array, correct_answer)\n",
    "        \n",
    "    answers = [correct_answer,\n",
    "               wrong_answer_1,\n",
    "               wrong_answer_2,\n",
    "               wrong_answer_3]\n",
    "    random.shuffle(answers)\n",
    "\n",
    "    d = {\"a\": answers[0],\n",
    "         \"b\": answers[1],\n",
    "         \"c\": answers[2],\n",
    "         \"d\": answers[3],\n",
    "        }\n",
    "\n",
    "    for choice in d.keys():\n",
    "        if d[choice] == correct_answer:\n",
    "            correct_choice = choice\n",
    "    \n",
    "    # question = f'''The tumor cell line named {cell_line_name} is\n",
    "    # question = f'''The tumor cell line named {cell_line_name} is a biological model for which primary disease?\n",
    "    question = f'''The cell line named {cell_line_name} is a biological model for which primary disease?\n",
    "\n",
    "a) {d['a']},\n",
    "b) {d['b']},\n",
    "c) {d['c']},\n",
    "d) {d['d']}.'''\n",
    "    \n",
    "    return question, correct_choice, correct_answer, cell_line_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb54595d-5113-40f4-bfd4-1fdc7575007d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done importing dataframe (rows, columns) = (1921, 36).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1921 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'You are a cancer research scientist studying the potential effects of various small molecules, peptides, and \\nantibiodies on tumor cell growth. You will be presented with a series of multiple choice questions. Please select the correct\\nchoice. Return the answer in json format {\"CHOICE\": choice, \"ANSWER\": answer} where choice is only the alphabetic character \\nassociated with the full answer.'}, {'role': 'user', 'content': 'The cell line named NIH:OVCAR-3 is a biological model for which primary disease?\\n\\na) Anaplastic Thyroid Cancer,\\nb) Invasive Breast Carcinoma,\\nc) Ovarian Epithelial Tumor,\\nd) Cervical Adenocarcinoma.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "PermissionDeniedError",
     "evalue": "<!DOCTYPE HTML>\n<html>\n\n<head>\n\n    <meta charset=\"utf-8\">\n\n    <title>Jupyter Server</title>\n    <link id=\"favicon\" rel=\"shortcut icon\" type=\"image/x-icon\" href=\"/static/favicon.ico?v=50afa725b5de8b00030139d09b38620224d4e7dba47c07ef0e86d4643f30c9bfe6bb7e1a4a1c561aa32834480909a4b6fe7cd1e17f7159330b6b5914bf45a880\">\n    \n    <link rel=\"stylesheet\" href=\"/static/style/bootstrap.min.css?v=0e8a7fbd6de23ad6b27ab95802a0a0915af6693af612bc304d83af445529ce5d95842309ca3405d10f538d45c8a3a261b8cff78b4bd512dd9effb4109a71d0ab\" />\n    <link rel=\"stylesheet\" href=\"/static/style/bootstrap-theme.min.css?v=8b2f045cb5b4d5ad346f6e816aa2566829a4f5f2783ec31d80d46a57de8ac0c3d21fe6e53bcd8e1f38ac17fcd06d12088bc9b43e23b5d1da52d10c6b717b22b3\" />\n    <link rel=\"stylesheet\" href=\"/static/style/index.css?v=30372e3246a801d662cf9e3f9dd656fa192eebde9054a2282449fe43919de9f0ee9b745d7eb49d3b0a5e56357912cc7d776390eddcab9dac85b77bdb17b4bdae\" />\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\" />\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n\n    \n\n    \n<style type=\"text/css\">\n    /* disable initial hide */\n    div#header,\n    div#site {\n        display: block;\n    }\n</style>\n\n\n    \n    \n\n</head>\n\n<body class=\"\"    dir=\"ltr\">\n\n  <noscript>\n    <div id='noscript'>\n      Jupyter Server requires JavaScript.<br>\n      Please enable it to proceed. \n    </div>\n  </noscript>\n\n  <div id=\"header\" role=\"navigation\" aria-label=\"Top Menu\">\n    <div id=\"header-container\" class=\"container\">\n      <div id=\"jupyter_server\" class=\"nav navbar-brand\"><a href=\"/tree\" title='dashboard'>\n          <img src='/static/logo/logo.png?v=a2a176ee3cee251ffddf5fa21fe8e43727a9e5f87a06f9c91ad7b776d9e9d3d5e0159c16cc188a3965e00375fb4bc336c16067c688f5040c0c2d4bfdb852a9e4' alt='Jupyter Server' />\n        </a></div>\n\n      \n      \n\n      \n      \n\n    </div>\n    <div class=\"header-bar\"></div>\n\n    \n    \n  </div>\n\n  <div id=\"site\">\n    \n\n<div class=\"error\">\n    \n    <h1>403 : Forbidden</h1>\n    \n    \n    \n    <p>The error was:</p>\n    <div class=\"traceback-wrapper\">\n        <pre class=\"traceback\">&#39;_xsrf&#39; argument missing from POST</pre>\n    </div>\n    \n    \n</div>\n\n\n  </div>\n\n  \n  \n\n  \n\n\n  <script type='text/javascript'>\n    function _remove_token_from_url() {\n      if (window.location.search.length <= 1) {\n        return;\n      }\n      var search_parameters = window.location.search.slice(1).split('&');\n      for (var i = 0; i < search_parameters.length; i++) {\n        if (search_parameters[i].split('=')[0] === 'token') {\n          // remote token from search parameters\n          search_parameters.splice(i, 1);\n          var new_search = '';\n          if (search_parameters.length) {\n            new_search = '?' + search_parameters.join('&');\n          }\n          var new_url = window.location.origin +\n            window.location.pathname +\n            new_search +\n            window.location.hash;\n          window.history.replaceState({}, \"\", new_url);\n          return;\n        }\n      }\n    }\n    _remove_token_from_url();\n  </script>\n</body>\n\n</html>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 51\u001b[0m\n\u001b[1;32m     41\u001b[0m messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     42\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     43\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: sys_reg_prompt\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m ]\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessages\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m chat_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# logprobs=1,\u001b[39;49;00m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# top_logprobs=1,\u001b[39;49;00m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#temperature=0.0,\u001b[39;49;00m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#max_tokens=2000,\u001b[39;49;00m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m printf(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchat_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/rbscratch/brettin/conda_envs/vLLM/lib/python3.9/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/rbscratch/brettin/conda_envs/vLLM/lib/python3.9/site-packages/openai/resources/chat/completions.py:663\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    661\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    662\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/rbscratch/brettin/conda_envs/vLLM/lib/python3.9/site-packages/openai/_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1188\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1195\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1196\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1197\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1198\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1199\u001b[0m     )\n\u001b[0;32m-> 1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/rbscratch/brettin/conda_envs/vLLM/lib/python3.9/site-packages/openai/_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    888\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/rbscratch/brettin/conda_envs/vLLM/lib/python3.9/site-packages/openai/_base_client.py:980\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    977\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    979\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 980\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m    983\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    984\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    987\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    988\u001b[0m )\n",
      "\u001b[0;31mPermissionDeniedError\u001b[0m: <!DOCTYPE HTML>\n<html>\n\n<head>\n\n    <meta charset=\"utf-8\">\n\n    <title>Jupyter Server</title>\n    <link id=\"favicon\" rel=\"shortcut icon\" type=\"image/x-icon\" href=\"/static/favicon.ico?v=50afa725b5de8b00030139d09b38620224d4e7dba47c07ef0e86d4643f30c9bfe6bb7e1a4a1c561aa32834480909a4b6fe7cd1e17f7159330b6b5914bf45a880\">\n    \n    <link rel=\"stylesheet\" href=\"/static/style/bootstrap.min.css?v=0e8a7fbd6de23ad6b27ab95802a0a0915af6693af612bc304d83af445529ce5d95842309ca3405d10f538d45c8a3a261b8cff78b4bd512dd9effb4109a71d0ab\" />\n    <link rel=\"stylesheet\" href=\"/static/style/bootstrap-theme.min.css?v=8b2f045cb5b4d5ad346f6e816aa2566829a4f5f2783ec31d80d46a57de8ac0c3d21fe6e53bcd8e1f38ac17fcd06d12088bc9b43e23b5d1da52d10c6b717b22b3\" />\n    <link rel=\"stylesheet\" href=\"/static/style/index.css?v=30372e3246a801d662cf9e3f9dd656fa192eebde9054a2282449fe43919de9f0ee9b745d7eb49d3b0a5e56357912cc7d776390eddcab9dac85b77bdb17b4bdae\" />\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\" />\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n\n    \n\n    \n<style type=\"text/css\">\n    /* disable initial hide */\n    div#header,\n    div#site {\n        display: block;\n    }\n</style>\n\n\n    \n    \n\n</head>\n\n<body class=\"\"    dir=\"ltr\">\n\n  <noscript>\n    <div id='noscript'>\n      Jupyter Server requires JavaScript.<br>\n      Please enable it to proceed. \n    </div>\n  </noscript>\n\n  <div id=\"header\" role=\"navigation\" aria-label=\"Top Menu\">\n    <div id=\"header-container\" class=\"container\">\n      <div id=\"jupyter_server\" class=\"nav navbar-brand\"><a href=\"/tree\" title='dashboard'>\n          <img src='/static/logo/logo.png?v=a2a176ee3cee251ffddf5fa21fe8e43727a9e5f87a06f9c91ad7b776d9e9d3d5e0159c16cc188a3965e00375fb4bc336c16067c688f5040c0c2d4bfdb852a9e4' alt='Jupyter Server' />\n        </a></div>\n\n      \n      \n\n      \n      \n\n    </div>\n    <div class=\"header-bar\"></div>\n\n    \n    \n  </div>\n\n  <div id=\"site\">\n    \n\n<div class=\"error\">\n    \n    <h1>403 : Forbidden</h1>\n    \n    \n    \n    <p>The error was:</p>\n    <div class=\"traceback-wrapper\">\n        <pre class=\"traceback\">&#39;_xsrf&#39; argument missing from POST</pre>\n    </div>\n    \n    \n</div>\n\n\n  </div>\n\n  \n  \n\n  \n\n\n  <script type='text/javascript'>\n    function _remove_token_from_url() {\n      if (window.location.search.length <= 1) {\n        return;\n      }\n      var search_parameters = window.location.search.slice(1).split('&');\n      for (var i = 0; i < search_parameters.length; i++) {\n        if (search_parameters[i].split('=')[0] === 'token') {\n          // remote token from search parameters\n          search_parameters.splice(i, 1);\n          var new_search = '';\n          if (search_parameters.length) {\n            new_search = '?' + search_parameters.join('&');\n          }\n          var new_url = window.location.origin +\n            window.location.pathname +\n            new_search +\n            window.location.hash;\n          window.history.replaceState({}, \"\", new_url);\n          return;\n        }\n      }\n    }\n    _remove_token_from_url();\n  </script>\n</body>\n\n</html>"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "df = load_data(f)\n",
    "array = df['OncotreePrimaryDisease'].unique()\n",
    "\n",
    "\n",
    "\n",
    "sys_reg_prompt = '''You are a cancer research scientist studying the potential effects of various small molecules, peptides, and \n",
    "antibiodies on tumor cell growth. You will be presented with a series of multiple choice questions. Please select the correct\n",
    "choice. Return the answer in json format {\"CHOICE\": choice, \"ANSWER\": answer} where choice is only the alphabetic character \n",
    "associated with the full answer.'''\n",
    "\n",
    "# This is not working yet because the experts talk to each other thus making the\n",
    "# parsing of the final answer different from the sys_reg_prompt.\n",
    "sys_tot_prompt = '''Imagine three experts are answering this question.\n",
    "They will brainstorm the answer step by step, reasoning carefully and taking all facts into consideration.\n",
    "All experts will write down one step of their thinking, then share it with the group.\n",
    "They will each critique their response and all the responses of others.\n",
    "They will check their answer based on science, laws of physics and logic.\n",
    "Then all experts will go on to the next step and write down this step of their thinking.\n",
    "They will keep going through steps until they reach their conclusions taking into account the thoughts of the other experts.\n",
    "If at anytime they realize that there is a flaw in their logic they will backtrack to where the flaw occurred.\n",
    "If any expert realizes they are wrong at any point they acknowledge this and start another train of thought.\n",
    "Each expert will assign a likelihood of their current assertion being correct.\n",
    "Continue until the experts agree on the single most likely choice. Return the response in json format FINAL_ANSWER={\"DISCUSSION\": discussion, \"CHOICE\": choice, \"ANSWER\": answer} where choice is only the alphabetic character \n",
    "associated with the full answer.'''\n",
    " \n",
    "for i in range(0, 9):\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    responses = []\n",
    "\n",
    "\n",
    "    for i in tqdm( range(df.shape[0]) ):\n",
    "        # get question, correct choice and answer\n",
    "        question, correct_choice, correct_answer, cell_line_name = construct_question(df, i, array)\n",
    "    \n",
    "        # construct message\n",
    "        messages=[\n",
    "            {\"role\": \"system\",\n",
    "             \"content\": sys_reg_prompt\n",
    "            },\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": question\n",
    "            },\n",
    "\n",
    "        ]\n",
    "        print(f'{messages}')\n",
    "        chat_response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            # logprobs=1,\n",
    "            # top_logprobs=1,\n",
    "            messages=messages,\n",
    "            #temperature=0.0,\n",
    "            #max_tokens=2000,\n",
    "            stream=False,\n",
    "        )\n",
    "        printf(f'{chat_response}')\n",
    "        \n",
    "        try:\n",
    "            response = json.loads(chat_response.choices[0].message.content)\n",
    "            response['CORRECT CHOICE'] = correct_choice\n",
    "            response['CORRECT ANSWER'] = correct_answer\n",
    "            response['CELL_LINE_NAME'] = cell_line_name\n",
    "    \n",
    "            if response['CHOICE'] == correct_choice:\n",
    "                response['SCORE'] = 1\n",
    "                num_correct = num_correct + 1\n",
    "            else:\n",
    "                response['SCORE'] = 0\n",
    "    \n",
    "            total = total + 1\n",
    "            responses.append(response)\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "            print(f\"{question}\")\n",
    "            print(f\"{chat_response.choices[0].message.content}\")\n",
    "\n",
    "            response[\"CHOICE\"] =  \"e\"\n",
    "            response[\"ANSWER\"] =  chat_response.choices[0].message.content\n",
    "            response['CORRECT CHOICE'] = correct_choice\n",
    "            response['CORRECT ANSWER'] = correct_answer\n",
    "            response['CELL_LINE_NAME'] = cell_line_name\n",
    "            response['SCORE'] = 0\n",
    "            \n",
    "            responses.append(response)\n",
    "            pass\n",
    "    \n",
    "    print(f'{num_correct} correct responses out of {total}')\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "    response_df = pd.DataFrame(responses)\n",
    "    response_df.to_csv(f'model_name_eval_{timestamp}.tsv', index=None, sep=\"\\t\")\n",
    "\n",
    "    #with open('model_name_eval_summary.txt', 'a') as f:\n",
    "    #    print(f'{timestamp}\\t{num_correct} correct responses out of {total}', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ec0dd-6877-43b8-8b05-3fb030868bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
